```{r settings, include=FALSE}
knitr::opts_chunk$set(fig.align='center', echo=FALSE, cache=FALSE)
```

```{r diagrams, include=FALSE}
library(diagram)
knitr::read_chunk("Code/diagrams.R")
```

# Build automation

Large projects can be a pain to manage. Small changes may break your software, 
or may deem your previously obtained analysis results useless. Build 
automation refers to a collection of tools that atempt to automate steps
in your workflow, thereby simplifying your the whole process. Many processes may
be automated, but here we will discuss two facets of build automation: 
project pipeline automation using Makefiles and automatic builds and checks of
your software using continuous integration tools.

## Makefiles

Most research projects consist of several different connected components. 
For example, the end product might be a manuscipt, which depends on intermediate
components such as a data analysis script and an R package. In this case, 
the manuscript depends on the data analysis script, which in turn depends on the
R package. Such a hierarchy implies that every time a file changes, all files 
downstream in the hierarchy should be updated as well. In the previous example, 
we might adjust a function in the R package, which might change the outcome of 
the data analysis, and as a result, we'd have to re-run the data analysis 
script. The outcome of the data analysis might change the manuscript, so we'd 
have to re-compile that as well. In large projects, this quickly becomes tedious
and difficult to maintain by hand. Luckily there is software available to 
streamline this process.

Consider the more complicated example in Figure \@ref(fig:workflow-diagram) with 
the following corresponding project directory:

```{bash example-directory, eval=FALSE, echo=TRUE}
./
├── rpackage
│   ├── DESCRIPTION
│   └── functions.R
├── code
│   ├── analysis.R
│   └── simulation.R
├── docs
│   ├── manuscript.Rnw
│   ├── presentation.Rnw
│   └── refs.bib
└── README.md
```

```{r workflow-diagram, fig.cap="Example project workflow"}
```

Re-running, -building, and -compiling all the files after we made a change to 
the anyone of the intermediate files would be a tedious task. Ideally, we would
like to have a command that re-runs/compiles/builds the different files 
everytime an upstream change is made. This is exactly what the GNU software Make 
does. Make works through a Makefile, a file that describes how a target file,
depends on its dependencies, and how these in turn on their dependencies, and so
on. If a Makefile is run, a file is compiled if any of its dependencies has 
changed since the last time the file was compiled. In other words, the Makefile
starts at the top of the hierarchy and updates a file if its creation time is 
older than the creation time of its dependencies. In our example in Figure
\@ref(fig:workflow-diagram), if we make a change to the functions.R file, we
trigger the recompilation of the recompilation of the r-package.tar.gz file, 
which in turn triggers a rerunning of the analysis.R and simulation.R scripts,
and so on, until all files are up to date again.

## Continuous integration

Did you ever wonder what the green/yellow/red 'badges' in some Readme.md files 
on, e.g., Github.com actually mean? How are they created, what are they for and 
why should you care?

This section will hopefully shed light on the meaning of some of these badges 
(those refering to a 'build status') and you will learn how to use these 
techniques for you own repositories. The key term here is 'continuous 
integration' (CI) which refers to a concept in software development where all 
working copies  (in git one would refer to branches) of a project are frequently
integrated into the mainline (in git terms: the master branch). The rationale 
being that frequent/continuous integration prevents diverging development 
branches. Since the philosophy of git is to create feature branches for small, 
contained changes of master which are to be merged back as soon as possible CI 
and git are a natural fit.

In practice, however, frequent changes to master are dangerous.  After all, the 
master branch should maintain the last at least working if not stable version of
the project that other feature branches can be started from. It is thus crucial 
to prevent erroneous changes to be merged into the master branch too often. This
means that CI requires some kind of automated quality checks that preemptively 
check for new bugs/problems before a pull request from a feature branch on 
master is executed. It is this particular aspect of CI that is most interesting 
to collaborative work on scientific coding projects - being able to 
automatically run checks/tests on pull requests proposing changes to the master 
branch of the 
project.

[Random thought: we should have an example repository for demonstraiting the 
different states of PRs etc. instead of just including pictures. Readers could 
then inspect the 'frozen' repository directly and see the PRs etc.!]

To enable this kind of feature on Github, a cloud-based farm or build servers is
required where users can run build scripts in virtual machines and retrieve 
reports on the build status (0 worked, 1 failed). It is these build-statuses 
that the green/yellow/red badges report visually (yellow/gray being a pending 
build)! There are multiple companies offering these services (within reasonable 
bounds) for free for public repositories and as of 2018 the free academic 
account for GitHub also enables free builds using TravisCI for private 
repositories. It must be stressed though that, since everything is running in 
the cloud, the same constraints as for storing data on GitHub servers apply to 
downloading or processing data in buildscripts for CI services. [point to 
Jenkins as on-premis solution]

The obvious setting to use automated builds in is package development. This is 
by far the most common application and the current tools are definitely geared 
towards that use case. We will later discuss how to extend the scope to 
non-package situations. For instance, the repository containing the source code 
for this book also uses TravisCI for build automation even though it is not an 
R-package itself.
